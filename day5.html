<!DOCTYPE html>
<html lang="ko">
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 집중력 확인 시스템 v3.0 (통합 알림)</title>
<style>
    body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    min-height: 100vh;
    margin: 0;
    padding: 20px;
    background-color: #f0f2f5;
    box-sizing: border-box;
}
    .wrapper {
    display: flex;
    gap: 20px;
    margin-bottom: 20px;
}
    .display-container {
    width: 480px;
    height: 360px;
    position: relative;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 8px 24px rgba(0,0,0,0.12);
    background-color: #000;
}
    .display-container h2 {
    position: absolute;
    top: 10px;
    left: 10px;
    margin: 0;
    padding: 5px 10px;
    background-color: rgba(0, 0, 0, 0.5);
    color: white;
    border-radius: 8px;
    font-size: 16px;
    z-index: 10;
}
    #webcam, #outputCanvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    transform: scaleX(-1);
}
    #status-box {
    padding: 16px 32px;
    border-radius: 12px;
    background-color: white;
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    text-align: center;
}
    #status-box h1 {
    margin: 0;
    font-size: 24px;
    color: #333;
}
    #status-text {
    font-size: 36px;
    font-weight: bold;
    margin-top: 8px;
    transition: color 0.3s ease;
}
</style>
<!-- MediaPipe 라이브러리 로드 -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
</head>
<body>
<div class="wrapper">
    <div class="display-container">
        <h2>원본 웹캠</h2>
        <video id="webcam" autoplay playsinline></video>
    </div>
    <div class="display-container">
        <h2>분석 영상</h2>
        <canvas id="outputCanvas" width="480" height="360"></canvas>
    </div>
</div>
<div id="status-box">
    <h1>현재 상태</h1>
    <p id="status-text">분석 중...</p>
</div>

<script type="module">
    const videoElement = document.getElementById('webcam');
    const canvasElement = document.getElementById('outputCanvas');
    const canvasCtx = canvasElement.getContext('2d');
    const statusTextElement = document.getElementById('status-text');

    // --- 상태 관리 및 타이머 설정 (통합 타이머로 변경) ---
    let currentState = '분석 중...';
    let nonFocusTime = 0; // '졸음'과 '주의 분산' 시간을 합산하여 저장
    let lastFrameTime = performance.now();
    let isAlertTriggered = false; // 알림은 한 번만 울리도록 관리

    const stateHistory = [];
    const HISTORY_SIZE = 10; // 10 프레임 수

    // --- 임계값 설정 (조정 가능) ---
    const YAW_THRESHOLD = 45; // 좌우 회전 머리각도
    const PITCH_THRESHOLD = 35; // 상하 회전 머리각도
    const EAR_THRESHOLD = 0.24;
    const ALERT_THRESHOLD_SECONDS = 120; // 2분 (2 * 60)

    const STATE_COLORS = {
    '집중': '#2ecc71', // 아래의 3가지 상태(자리 비움, 주의 분산, 졸음)에 해당하지 않을 때의 기본 상태
    '주의 분산': '#f39c12', //머리각도 HEAD POSE가 정면을 벗어났을 때
    '졸음': '#3498db', // 눈을 감거나 게슴츠레하게 떠있을 때
    '자리 비움': '#95a5a6', // 얼굴을 전혀 감지하지 못할 때
    '분석 중...': '#34495e'
};

    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    function playAlertSound() {
    if (audioContext.state === 'suspended') {
    audioContext.resume();
}
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();
    oscillator.connect(gainNode);
    gainNode.connect(audioContext.destination);
    oscillator.type = 'sine';
    oscillator.frequency.setValueAtTime(440, audioContext.currentTime);
    gainNode.gain.setValueAtTime(0.5, audioContext.currentTime);
    oscillator.start(audioContext.currentTime);
    oscillator.stop(audioContext.currentTime + 0.5);
}

    function getHeadPose(landmarks, width, height) {
    const nose_x = landmarks[1].x * width;
    const left_eye_x = landmarks[263].x * width;
    const right_eye_x = landmarks[33].x * width;
    const chin_y = landmarks[152].y * height;
    const nose_y = landmarks[1].y * height;
    const eye_center_x = (left_eye_x + right_eye_x) / 2;
    const yaw = (nose_x - eye_center_x) / (right_eye_x - left_eye_x) * 90;
    const pitch = (nose_y - chin_y) / (height * 0.4) * 90;
    return { yaw, pitch };
}

    function calculateEAR(eyeLandmarks) {
    const dist = (pA, pB) => Math.hypot(pA.x - pB.x, pA.y - pB.y);
    return (dist(eyeLandmarks[1], eyeLandmarks[5]) + dist(eyeLandmarks[2], eyeLandmarks[4])) / (2.0 * dist(eyeLandmarks[0], eyeLandmarks[3]));
}

    function onResults(results) {
    const now = performance.now();
    const deltaTime = (now - lastFrameTime) / 1000;
    lastFrameTime = now;

    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

    let rawState = '집중';

    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
    const landmarks = results.multiFaceLandmarks[0];
    drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, { color: '#C0C0C070', lineWidth: 1 });

    const { yaw, pitch } = getHeadPose(landmarks, canvasElement.width, canvasElement.height);
    if (Math.abs(yaw) > YAW_THRESHOLD || Math.abs(pitch) > PITCH_THRESHOLD) {
    rawState = '주의 분산';
}

    const leftEyeIndices = [33, 160, 158, 133, 153, 144];
    const rightEyeIndices = [362, 385, 387, 263, 373, 380];
    const leftEAR = calculateEAR(leftEyeIndices.map(i => landmarks[i]));
    const rightEAR = calculateEAR(rightEyeIndices.map(i => landmarks[i]));
    const avgEAR = (leftEAR + rightEAR) / 2.0;

    if (avgEAR < EAR_THRESHOLD) {
    rawState = '졸음';
}
} else {
    rawState = '자리 비움';
}

    updateState(rawState, deltaTime);
    canvasCtx.restore();
}

    function updateState(rawState, deltaTime) {
    stateHistory.push(rawState); // 현재 프레임 상태를 맨 뒤에 추가
    // 길이가 10을 넘으면 큐 형식으로 오래된 기억을 제거
    if (stateHistory.length > HISTORY_SIZE) stateHistory.shift();

    // 상태를 최종 확정
    if (stateHistory.length === HISTORY_SIZE && stateHistory.every(s => s === stateHistory[0])) {
    const stableState = stateHistory[0];
    if (currentState !== stableState) {
    currentState = stableState;
    statusTextElement.textContent = currentState;
    statusTextElement.style.color = STATE_COLORS[currentState];
}

    // --- 로직 변경 지점 ---
    // '졸음' 또는 '주의 분산' 상태일 때 통합 타이머를 증가
    if (stableState === '졸음' || stableState === '주의 분산') {
    nonFocusTime += deltaTime;
} else {
    // '집중' 또는 '자리 비움' 상태가 되면 타이머와 알림 플래그를 리셋
    nonFocusTime = 0;
    isAlertTriggered = false;
}

    // 통합된 타이머를 기준으로 알림 조건 확인
    if (nonFocusTime > ALERT_THRESHOLD_SECONDS && !isAlertTriggered) {
    playAlertSound();
    isAlertTriggered = true; // 알림이 반복해서 울리는 것을 방지
    console.log(`경고: ${ALERT_THRESHOLD_SECONDS}초 이상 비집중 상태가 감지되었습니다.`);
}
}
}

    // --- MediaPipe 및 카메라 초기화 ---
    const faceMesh = new FaceMesh({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
});
    faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
});
    faceMesh.onResults(onResults);

    const camera = new Camera(videoElement, {
    onFrame: async () => {
    if (audioContext.state === 'suspended') {
    audioContext.resume();
}
    await faceMesh.send({ image: videoElement });
},
    width: 480,
    height: 360
});
    camera.start();

</script>
</body>
</html>
